# assistant408

  <div align="center">
    <img src="./assets/computer.png" width="200"/></br>
    <b><font size="5">assistant408</font></b></br></br>
    <b><font size="5">åŸºäºInternlm2-chat-7bæ¨¡å‹çš„408è€ƒç ”å°åŠ©æ‰‹</font></b>
  </div>


## ğŸ–Šï¸ ç›®å½•
- [ğŸ“– ç®€ä»‹](#-ç®€ä»‹)
- [ğŸš€ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
  * [çŸ¥è¯†åº“](#-çŸ¥è¯†åº“)
  * [å¾®è°ƒ](#-å¾®è°ƒ)
    + [å‡†å¤‡æ•°æ®é›†](#-å‡†å¤‡æ•°æ®é›†)
    + [å‡†å¤‡é…ç½®æ–‡ä»¶](#-å‡†å¤‡é…ç½®æ–‡ä»¶)
    + [ä¿®æ”¹é…ç½®æ–‡ä»¶](#-ä¿®æ”¹é…ç½®æ–‡ä»¶)
    + [å¼€å§‹è®­ç»ƒ](#-å¼€å§‹è®­ç»ƒ)
    + [è½¬æ¢æ ¼å¼](#-è½¬æ¢æ ¼å¼)
    + [æ¨¡å‹åˆå¹¶](#-æ¨¡å‹åˆå¹¶)
    + [æ¨¡å‹è¿è¡Œ](#-æ¨¡å‹è¿è¡Œ)
  * [æ¨¡å‹é‡åŒ–](#-æ¨¡å‹é‡åŒ–)
  * [æ¨¡å‹è¯„æµ‹](#-æ¨¡å‹è¯„æµ‹)
- [ğŸ™‚ é¡¹ç›®æˆå‘˜](#-é¡¹ç›®æˆå‘˜)
- [ğŸ’• è‡´è°¢](#-è‡´è°¢)



## ğŸ“– ç®€ä»‹
&emsp;&emsp;assistant408ï¼ˆè€ƒç ”408è®¡ç®—æœºå­¦ç§‘ä¸“ä¸šåŸºç¡€ç»¼åˆçš„å°åŠ©æ‰‹ï¼‰æ˜¯ä¸€ä¸ªé›†æˆ 408 è€ƒç ”çŸ¥è¯†åŠè§£ç­”èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹ã€‚
> 408å…¨ç§°è®¡ç®—æœºä¸“ä¸šåŸºç¡€ç»¼åˆï¼Œå…±åŒ…æ‹¬å››é—¨ä¸“ä¸šè¯¾çš„è€ƒå¯Ÿï¼Œåˆ†åˆ«æ˜¯æ•°æ®ç»“æ„ã€è®¡ç®—æœºç»„æˆåŸç†ã€æ“ä½œç³»ç»Ÿå’Œè®¡ç®—æœºç½‘ç»œã€‚
> |  è€ƒè¯•ç§‘ç›®  |   æ•°æ®ç»“æ„   |   è®¡ç®—æœºç»„æˆåŸç†   | æ“ä½œç³»ç»Ÿ | è®¡ç®—æœºç½‘ç»œ |
>|:------:|:------:|:-------:|:-------:|:-------:|
> |åˆ†æ•°|45åˆ†|45åˆ†|35åˆ†|25åˆ†|
> |è€ƒè¯•å æ¯”|30%|30%|23%|17%|

&emsp;&emsp;è¯¥æ¨¡å‹åŸºäºInternlm2-chat-7båŸºåº§æ¨¡å‹ï¼Œä½¿ç”¨æ¨¡å‹å®¹æ˜“å‡ºé”™çš„æ¦‚å¿µæ€§é¢˜ç›®è¿›è¡Œå¾®è°ƒï¼Œå†ä½¿ç”¨GPTç”Ÿæˆçš„400é“é¢˜ç›®è¿›è¡Œè¯„æµ‹ï¼Œå¾—åˆ°äº†è¾ƒå¥½çš„æ•ˆæœã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹
### ğŸ“ çŸ¥è¯†åº“
&emsp;&emsp;åœ¨æœ¬æ¬¡çŸ¥è¯†åº“æ­å»ºä¸­ç”¨åˆ°äº†å¦‚ä¸‹çŸ¥è¯†ï¼Œæœ‰éœ€è¦çš„å¯ä»¥è‡ªè¡Œå‰å¾€ä¸‹è½½ï¼Œåœ¨æœ¬ä»“åº“ data_base/vector_db/chroma ç›®å½•ä¸‹å·²ç»ä¸ºå¤§å®¶æ­å»ºå¥½äº†è®­ç»ƒåçš„çŸ¥è¯†åº“ï¼Œå¯ä»¥å°†æœ¬ä»“åº“ clone åˆ°æœ¬åœ°ã€‚
- [x] 25ç‹é“è€ƒç ”æ•°æ®ç»“æ„
- [x] 25ç‹é“è€ƒç ”è®¡ç®—æœºç»„æˆåŸç†
- [x] 25ç‹é“è€ƒç ”æ“ä½œç³»ç»Ÿ
- [x] 25ç‹é“è€ƒç ”è®¡ç®—æœºç½‘ç»œ
- [x] ...
```bash
git clone https://github.com/zgiggle/assistant408.git
```

&emsp;&emsp;å¦‚æœéœ€è¦è‡ªå®šä¹‰çŸ¥è¯†åº“ï¼Œå¯ä»¥å‚è€ƒcreate_db.pyï¼Œé¦–å…ˆå°†æœ¬åœ°çŸ¥è¯†åº“é€šè¿‡Unstructed Loaderè½¬åŒ–ä¸ºçº¯æ–‡æœ¬æ ¼å¼ï¼Œçº¯æ–‡æœ¬å†ç»è¿‡Text Splitteråˆ†ä¸ºChunksï¼Œé€šè¿‡Sentence Transformerè½¬åŒ–ä¸ºå‘é‡æ ¼å¼å¹¶å­˜æ”¾åœ¨Chromaå‘é‡æ•°æ®åº“ä¸­ã€‚å¯¹äºç”¨æˆ·çš„è¾“å…¥åŒæ ·é€šè¿‡Sentence Transformerè½¬ä¸ºå‘é‡æ ¼å¼ï¼Œå†ä¸å‘é‡æ•°æ®åº“è¿›è¡Œç›¸ä¼¼åº¦åŒ¹é…ï¼Œæ‰¾åˆ°ä¸ç”¨æˆ·è¾“å…¥ç›¸å…³çš„æ–‡æœ¬æ®µï¼Œæœ€åå°†æ–‡æœ¬æ®µåµŒå…¥åˆ°å†™å¥½çš„Prompt Templateä¸­å¹¶äº¤ç»™InternLMå›ç­”ã€‚è¿™æ•´ä¸ªè¿‡ç¨‹éƒ½ä¼šè¢«å°è£…åœ¨æ£€ç´¢é—®ç­”æµä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¸ªæ€§åŒ–é…ç½®å¼•å…¥æ£€ç´¢é—®ç­”æµä¸­ï¼Œå°±èƒ½æ­å»ºå±äºè‡ªå·±çš„RAGåº”ç”¨ã€‚  

&emsp;&emsp;ç›®å½•ä¸‹çš„LLM.pyæ–‡ä»¶ç”¨äºè‡ªå®šä¹‰LLMç±»ï¼Œåœ¨ç»ˆç«¯ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤å³å¯è¿è¡Œé£Ÿç”¨ï¼ˆæ³¨æ„ä¿®æ”¹run_internlm.pyä¸­çš„æ¨¡å‹åœ°å€ï¼‰ã€‚
```bash
python run_internlm.py
```

### ğŸ“ å¾®è°ƒ
__1. å‡†å¤‡æ•°æ®é›†__
&emsp;&emsp;åœ¨æœ¬ä»“åº“çš„ data/xtuner_data ç›®å½•ä¸‹å·²ç»å‡†å¤‡å¥½äº†è®­ç»ƒçš„æ•°æ®é›†ï¼Œå¾®è°ƒæ•°æ®é›†ç»“æ„å¦‚ä¸‹ã€‚
```text
input: è®¡ç®—æœºä¸­ï¼Œæµ®ç‚¹æ•°çš„æŒ‡æ•°éƒ¨åˆ†é€šå¸¸é‡‡ç”¨ä»€ä¹ˆæ–¹å¼è¿›è¡Œç¼–ç ï¼Ÿ
output: ç§»ç ã€‚
input: å“ªç§ç±»å‹çš„å­˜å‚¨å™¨é€šå¸¸è¢«ç”¨ä½œè®¡ç®—æœºçš„ä¸»å­˜å‚¨å™¨ï¼Ÿ
output: SRAMã€‚
input: åœ¨è®¡ç®—æœºç³»ç»Ÿä¸­ï¼Œä¸€ä¸ª32ä½çš„æŒ‡ä»¤é•¿åº¦æ„å‘³ç€ä»€ä¹ˆï¼Ÿ
output: æŒ‡ä»¤çš„é•¿åº¦æ˜¯32ä½ã€‚
input: ä»€ä¹ˆæ˜¯è¡¡é‡CPUæ€§èƒ½çš„ä¸€ä¸ªé‡è¦æŒ‡æ ‡ï¼Ÿ
output: æ—¶é’Ÿé¢‘ç‡ã€æ ¸å¿ƒæ•°ã€ç¼“å­˜å¤§å°ã€‚
input: è¯·åšä¸€ä¸‹è‡ªæˆ‘ä»‹ç»ã€‚
output: ä½ å¥½,æˆ‘æ˜¯è€ƒç ”408è®¡ç®—æœºå­¦ç§‘ä¸“ä¸šåŸºç¡€ç»¼åˆçš„å°åŠ©æ‰‹å“¦ã€‚
```

__2. å‡†å¤‡é…ç½®æ–‡ä»¶__
```bash
mkdir /root/personal_assistant/config/question && cd /root/personal_assistant/config/question
xtuner copy-cfg internlm2_chat_7b_qlora_oasst1_e3 .
```

__3. ä¿®æ”¹é…ç½®æ–‡ä»¶__
```python
# ä¿®æ”¹æ¨¡å‹ä¸ºæœ¬åœ°è·¯å¾„
pretrained_model_name_or_path = '/root/share/module_repos/internlm2-chat-7b'

# ä¿®æ”¹è®­ç»ƒæ•°æ®é›†ä¸ºæœ¬åœ°è·¯å¾„
data_path = '/root/personal_assistant/data/xtuner_data/answer2.json'

# ä¿®æ”¹é…ç½®æ–‡ä»¶PART 1å‚æ•°
max_length = 2048
max_epochs = 12
evaluation_freq = 90
SYSTEM = 'æ‚¨æ˜¯è€ƒç ”408è®¡ç®—æœºå­¦ç§‘ä¸“ä¸šåŸºç¡€ç»¼åˆå°åŠ©æ‰‹ï¼Œæ‚¨å§‹ç»ˆæ ¹æ®æé—®è€…çš„é—®é¢˜æä¾›å‡†ç¡®ã€å…¨é¢å’Œè¯¦ç»†çš„ç­”æ¡ˆã€‚'
evaluation_inputs = [
    'è¯·åšä¸€ä¸‹è‡ªæˆ‘ä»‹ç»',
    'è®¡ç®—æœºä¸­ï¼Œæµ®ç‚¹æ•°çš„æŒ‡æ•°éƒ¨åˆ†é€šå¸¸é‡‡ç”¨ä»€ä¹ˆæ–¹å¼è¿›è¡Œç¼–ç ', 
    'åœ¨è®¡ç®—æœºç³»ç»Ÿä¸­ï¼Œä¸­æ–­çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ',
    'åœ¨æ“ä½œç³»ç»Ÿä¸­ï¼Œæ­»é”å‘ç”Ÿçš„å¿…è¦æ¡ä»¶ä¹‹ä¸€æ˜¯ï¼š',
    'å“ªç§è®¾å¤‡ä¸é€‚åˆä½¿ç”¨ç¼“å†²åŒºï¼ˆBufferï¼‰æŠ€æœ¯ï¼Ÿ',
    'åœ¨è®¡ç®—æœºç³»ç»Ÿä¸­ï¼Œä»€ä¹ˆå†³å®šäº†è®¡ç®—æœºæ‰§è¡ŒæŒ‡ä»¤çš„é€Ÿåº¦ï¼Ÿ'
]

# ä¿®æ”¹é…ç½®æ–‡ä»¶PART 3å‚æ•°
dataset=dict(type=load_dataset, path='json', data_files=dict(train=data_path))
dataset_map_fn=None

```

__4. å¼€å§‹è®­ç»ƒ__
```bash
cd /root/personal_assistant/config/question
xtuner train internlm2_chat_7b_qlora_oasst1_e3_copy.py
```
__5. pthæ ¼å¼è½¬æ¢ä¸ºhugging faceæ ¼å¼__
```bash
mkdir /root/personal_assistant/config/question/work_dirs/hf
export MKL_SERVICE_FORCE_INTEL=1

# é…ç½®æ–‡ä»¶å­˜æ”¾çš„ä½ç½®
export CONFIG_NAME_OR_PATH=/root/personal_assistant/config/question/internlm2_chat_7b_qlora_oasst1_e3_copy.py

# æ¨¡å‹è®­ç»ƒåå¾—åˆ°çš„pthæ ¼å¼å‚æ•°å­˜æ”¾çš„ä½ç½®
export PTH=/root/personal_assistant/config/question/work_dirs/internlm2_chat_7b_qlora_oasst1_e3_copy/iter_384.pth

# pthæ–‡ä»¶è½¬æ¢ä¸ºHugging Faceæ ¼å¼åå‚æ•°å­˜æ”¾çš„ä½ç½®
export SAVE_PATH=/root/personal_assistant/config/question/work_dirs/hf

# æ‰§è¡Œå‚æ•°è½¬æ¢
xtuner convert pth_to_hf $CONFIG_NAME_OR_PATH $PTH $SAVE_PATH
```
__6. æ¨¡å‹åˆå¹¶__
```bash
export MKL_SERVICE_FORCE_INTEL=1
export MKL_THREADING_LAYER='GNU'

# åŸå§‹æ¨¡å‹å‚æ•°å­˜æ”¾çš„ä½ç½®
export NAME_OR_PATH_TO_LLM=/root/share/model_repos/internlm2-chat-7b

# Hugging Faceæ ¼å¼å‚æ•°å­˜æ”¾çš„ä½ç½®
export NAME_OR_PATH_TO_ADAPTER=/root/personal_assistant/config/question/work_dirs/hf

# æœ€ç»ˆMergeåçš„å‚æ•°å­˜æ”¾çš„ä½ç½®
mkdir /root/personal_assistant/config/question/work_dirs/hf_merge
export SAVE_PATH=/root/personal_assistant/config/question/work_dirs/hf_merge

# æ‰§è¡Œå‚æ•°Merge
xtuner convert merge \
    $NAME_OR_PATH_TO_LLM \
    $NAME_OR_PATH_TO_ADAPTER \
    $SAVE_PATH \
--max-shard-size 2GB
```
__7. æ¨¡å‹è¿è¡Œ__  
&emsp;&emsp;æä¾›ä¸¤ç§è¿è¡Œæ–¹å¼ï¼Œç¬¬ä¸€ç§æ–¹å¼ä¸ºè¿è¡Œweb_demo.pyï¼Œé¦–å…ˆä¿®æ”¹æ¨¡å‹è·¯å¾„ä¸ºåˆå¹¶åçš„å¾®è°ƒæ¨¡å‹ï¼Œå†è¿›è¡Œè¿è¡Œã€‚
```python
model = (AutoModelForCausalLM.from_pretrained('/root/personal_assistant/config/question/work_dirs/hf_merge',
                                                  trust_remote_code=True).to(
                                                      torch.bfloat16).cuda())
tokenizer = AutoTokenizer.from_pretrained('/root/personal_assistant/config/question/work_dirs/hf_merge',
                                              trust_remote_code=True)
```
```bash
# å¼€å§‹è¿è¡Œ
cd /root/personal_assistant/code/InternLM/chat
streamlit run web_demo.py --server.address 127.0.0.1 --server.port 7860
```
&emsp;&emsp;è¿è¡Œæ•ˆæœå¦‚ä¸‹ï¼š  
<img src="assets/web_demo.png" width="100%">

&emsp;&emsp;ç¬¬äºŒç§æ–¹å¼ä¸ºè¿è¡Œrun_internlm.pyï¼Œé¦–å…ˆä¿®æ”¹æ¨¡å‹è·¯å¾„ä¸ºåˆå¹¶åçš„å¾®è°ƒæ¨¡å‹ï¼Œå†è¿›è¡Œè¿è¡Œã€‚
```python
llm = InternLM_LLM(model_path = "/root/personal_assistant/config/question/work_dirs/hf_merge")
```
```bash
# å¼€å§‹è¿è¡Œ
python run_internlm.py
```
&emsp;&emsp;è¿è¡Œæ•ˆæœå¦‚ä¸‹ï¼š  
<img src="assets/run_gradio.png" width="100%">

### ğŸ“ æ¨¡å‹é‡åŒ–  
&emsp;&emsp;ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œé‡åŒ–å¹¶è¿è¡Œï¼š
```bash
# å¼€å§‹W4A16é‡åŒ–
export HF_MODEL=/root/personal_assistant/config/question/work_dirs/hf_merge
export WORK_DIR=/root/personal_assistant/model/internlm2_chat_7b_4bit

lmdeploy lite auto_awq \
   $HF_MODEL \
  --calib-dataset 'ptb' \
  --calib-samples 128 \
  --calib-seqlen 2048 \
  --w-bits 4 \
  --w-group-size 128 \
  --work-dir $WORK_DIR
```
&emsp;&emsp;ä½¿ç”¨lmdeploy chatå³å¯å¿«é€Ÿä½“éªŒé‡åŒ–åçš„ç»“æœï¼Œå¯ä»¥æ˜æ˜¾å°† 19G æ˜¾å­˜å ç”¨é™ä½


### ğŸ“ æ¨¡å‹è¯„æµ‹
&emsp;&emsp;é¦–å…ˆï¼Œæˆ‘ä»¬å›¢é˜Ÿå¯¹å¾®è°ƒå‰æ¨¡å‹å’Œå¾®è°ƒå+å‘é‡æ•°æ®åº“æ¨¡å‹åˆ†åˆ«è¿›è¡Œ 400 é“ 408 è€ƒé¢˜çš„æµ‹è¯•ï¼Œå…¶ä¸­æ¯é—¨ç§‘ç›® 100 é“ï¼Œå…¶ä¸­æµ‹è¯•é¢˜ç”±GPTç»™å‡ºï¼Œæµ‹è¯•é¢˜å¯ä»¥åœ¨ data/test_data è·å–ã€‚
|  æ­£ç¡®ç‡  |   æ•°æ®ç»“æ„   |   è®¡ç®—æœºç»„æˆåŸç†   | æ“ä½œç³»ç»Ÿ | è®¡ç®—æœºç½‘ç»œ |
|:------:|:------:|:-------:|:-------:|:-------:|
|è®­ç»ƒå‰æ¨¡å‹|--|--|--|--|
|è®­ç»ƒåæ¨¡å‹|85%|86%|79%|90%|

&emsp;&emsp;ç»è¿‡æµ‹è¯•å‘ç°ï¼Œè®­ç»ƒåçš„æ¨¡å‹èƒ½å¤Ÿå¿«é€Ÿå“åº”ï¼Œå¹¶ç»™å‡ºç­”æ¡ˆï¼Œæ­£ç¡®ç‡è¾ƒé«˜ï¼Œè€Œè®­ç»ƒå‰æ¨¡å‹å“åº”é€Ÿåº¦æ…¢ï¼Œå‡†ç¡®ç‡ä½ï¼Œå“åº”å†…å®¹å¤šè€Œæ‚ï¼Œä¸æ˜¯æƒ³è¦çš„ç»“æœã€‚  
&emsp;&emsp;è®­ç»ƒå‰æ¨¡å‹å“åº”æ•ˆæœï¼š  
<img src="assets/before_train1.png" width="90%">  
<img src="assets/before_train2.png" width="100%">

&emsp;&emsp;è®­ç»ƒåæ¨¡å‹å“åº”æ•ˆæœï¼š  
<img src="assets/run_gradio.png" width="100%">

&emsp;&emsp;æœ€åï¼Œæˆ‘ä»¬è¿›è¡Œäº†opencompassè¯„æµ‹ï¼Œé¦–å…ˆç¯å¢ƒå‡†å¤‡ï¼š
```bash
# ç¯å¢ƒå‡†å¤‡
git clone https://github.com/open-compass/opencompass
cd opencompass
pip install -e .

# æ•°æ®å‡†å¤‡
cp /share/temp/datasets/OpenCompassData-core-20231110.zip /root/opencompass/
unzip OpenCompassData-core-20231110.zip
```
&emsp;&emsp;è¿›å…¥ç¯å¢ƒå‡†å¤‡çš„ç›®å½•ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼ŒæŸ¥çœ‹æ”¯æŒçš„æ¨¡å‹å’Œæ•°æ®é›†ã€‚
```bash
python tools/list_configs.py internlm ceval
```
&emsp;&emsp;æ”¯æŒçš„æ¨¡å‹å¦‚ä¸‹ï¼Œé€‰æ‹©é€‚é…çš„internlm2-chat-7bæ¨¡å‹ï¼š  
<img src="assets/opencompass_model.png" width="100%">
&emsp;&emsp;æ”¯æŒçš„æ•°æ®é›†å¦‚ä¸‹ï¼š  
<img src="assets/opencompass_data.png" width="100%">
&emsp;&emsp;è¯„æµ‹çš„ç»“æœä½äºopencompass/after_train.csv



## â€â€â€â€â€ğŸ™‚ é¡¹ç›®æˆå‘˜
- å¼ ä¸°ç‘ï¼Œä¸»è¦è´Ÿè´£æ¨¡å‹å¾®è°ƒã€é‡åŒ–ã€è¯„æµ‹ã€‚
- æ¨é˜³ï¼Œä¸»è¦è´Ÿè´£ 408 é¢˜ç›®æ”¶é›†å’Œè¯„æµ‹ã€‚
- å‘¨æ®·ç¨·ï¼Œä¸»è¦è´Ÿè´£çŸ¥è¯†åº“æ”¶é›†ï¼Œå‘é‡æ•°æ®åº“æ­å»ºã€‚
- æ›¹ä¸€å‡¡ï¼Œä¸»è¦è´Ÿè´£æ”¶é›†å¾®è°ƒæ•°æ®å¹¶å¾®è°ƒã€‚

## ğŸ’• è‡´è°¢
<div align="center">

**æ„Ÿè°¢ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ç»„ç»‡çš„ ä¹¦ç”ŸÂ·æµ¦è¯­å®æˆ˜è¥ å­¦ä¹ æ´»åŠ¨ ä¸ ç®—åŠ›æ”¯æŒ~**

</div>











